
# ğŸ† Pipeline de Dados End-to-End com Azure Databricks

## ğŸ“‹ VisÃ£o Geral do Projeto

Este projeto demonstra a implementaÃ§Ã£o de uma arquitetura de dados moderna e escalÃ¡vel utilizando **Azure Databricks** com a metodologia **Medallion Architecture**. O projeto simula um cenÃ¡rio real de e-commerce, processando dados de **vendas**, **produtos**, **clientes** e **regiÃµes** atravÃ©s de pipelines automatizados que seguem as melhores prÃ¡ticas da engenharia de dados moderna.

![Excalidraw](https://raw.githubusercontent.com/ViniciusLabruna/pipeline-vendas-azure-databricks/main/excalidraw_databricks_pipeline.png)

---

## ğŸ¯ Objetivos Principais

- Implementar uma arquitetura de dados robusta e escalÃ¡vel na nuvem Azure  
- Aplicar conceitos avanÃ§ados de engenharia de dados usando ferramentas de ponta  
- Demonstrar expertise em processamento de dados em tempo real e batch  
- Construir pipelines de dados automatizados e reutilizÃ¡veis  

---

## ğŸ—ï¸ Arquitetura do Projeto

**Medallion Architecture** â†’ Bronze â†’ Silver â†’ Gold â†’ Power BI

```mermaid
graph TD
    A[ğŸ“ Source Data (Parquet)] --> B[ğŸ¥‰ Bronze Layer (Raw Data Ingestion)]
    B --> C[ğŸ¥ˆ Silver Layer (Data Transformation & Quality)]
    C --> D[ğŸ¥‡ Gold Layer (Business-Ready Analytics)]
    D --> E[ğŸ“Š Power BI Dashboard]
```

![Diagrama da Arquitetura](https://raw.githubusercontent.com/ViniciusLabruna/pipeline-vendas-azure-databricks/main/azure_databricks_pipeline.png)

---

## ğŸ› ï¸ Stack TecnolÃ³gico

### ğŸ”¹ Cloud & Plataforma de Dados
- **Azure Databricks** â€“ Plataforma de analytics unificada
- **Azure Data Lake Storage Gen2** â€“ Data Lake escalÃ¡vel
- **Unity Catalog** â€“ GovernanÃ§a de dados centralizada
- **Delta Lake** â€“ Storage layer otimizado para analytics

### ğŸ”¹ Linguagens & Frameworks
- **Python** â€“ Linguagem principal para transformaÃ§Ãµes
- **PySpark** â€“ Processamento distribuÃ­do de big data
- **SQL** â€“ Queries analÃ­ticas e transformaÃ§Ãµes
- **Delta Live Tables** â€“ Framework declarativo para ETL

### ğŸ”¹ Ferramentas de Desenvolvimento
- **Databricks Notebooks** â€“ Ambiente colaborativo de desenvolvimento
- **Databricks Workflows** â€“ OrquestraÃ§Ã£o de pipelines
- **Azure Resource Manager (ARM)** â€“ Infraestrutura como cÃ³digo

---

## ğŸ”§ Componentes TÃ©cnicos Implementados

### 1. ğŸ¥‰ Bronze Layer â€“ IngestÃ£o de Dados

```python
df = spark.readStream.format("cloudFiles") \
  .option("cloudFiles.format", "parquet") \
  .option("cloudFiles.schemaLocation", f"abfss://bronze@databricksete1956.dfs.core.windows.net/checkpoint_{p_file_name}") \
  .load(f"abfss://source@databricksete1956.dfs.core.windows.net/{p_file_name}")
```

**TÃ©cnicas:**
- Auto Loader â€“ IngestÃ£o incremental
- Schema Evolution â€“ AdaptaÃ§Ã£o automÃ¡tica a mudanÃ§as
- Checkpointing â€“ Exactly-once processing

---

### 2. ğŸ¥ˆ Silver Layer â€“ TransformaÃ§Ã£o e Qualidade

```python
from pyspark.sql.functions import *
from pyspark.sql.types import *

df_with_discount = df.withColumn("discounted_price", col("price") * 0.9)
df_cleaned = df.withColumn("brand_standardized", upper(col("brand")))
```

**TÃ©cnicas:**
- Data Quality Checks
- Window Functions
- Column Transformations
- Domain Extraction

---

### 3. ğŸ¥‡ Gold Layer â€“ Modelagem Dimensional

```python
def create_scd_type2_table(df_new, table_name):
    # Identificar registros novos e alterados
    # Criar surrogate keys
    # Manter histÃ³rico de mudanÃ§as
    pass
```

**TÃ©cnicas AvanÃ§adas:**
- Star Schema
- SCD Type 2 (Slowly Changing Dimensions)
- Surrogate Keys
- Delta Live Tables

---

### 4. ğŸ” Funcionalidades DinÃ¢micas

```python
datasets = [
    {"file_name": "orders"},
    {"file_name": "customers"},
    {"file_name": "products"}
]
dbutils.jobs.taskValues.set("output_datasets", datasets)
```

---

## ğŸ“Š BenefÃ­cios TÃ©cnicos

### ğŸ§  Performance & Escalabilidade
- Particionamento Inteligente
- Z-Ordering
- Caching
- Compute Autoscaling

### ğŸ”’ Confiabilidade & Qualidade
- ACID Transactions
- Time Travel
- Data Lineage
- Automated Testing

### ğŸ›¡ï¸ GovernanÃ§a & SeguranÃ§a
- Unity Catalog
- Column-Level Security
- Audit Logging
- Data Classification

---

## ğŸ”„ Pipelines Implementados

### ğŸ”¹ Pipeline de IngestÃ£o (Bronze)
âœ… Streaming com Autoloader  
âœ… Schema evolution  
âœ… Checkpointing  
âœ… Monitoramento contÃ­nuo  

### ğŸ”¹ Pipeline de TransformaÃ§Ã£o (Silver)
âœ… Limpeza e padronizaÃ§Ã£o  
âœ… Regras de negÃ³cio  
âœ… MÃ©tricas derivadas  
âœ… ValidaÃ§Ã£o de qualidade  

### ğŸ”¹ Pipeline AnalÃ­tico (Gold)
âœ… Tabelas dimensionais  
âœ… SCD Type 2  
âœ… OtimizaÃ§Ãµes analÃ­ticas  
âœ… AgregaÃ§Ãµes prÃ©-computadas  

---

## ğŸ“ Estrutura do Projeto

```bash
pipeline-vendas-azure-databricks/
â”œâ”€â”€ README.md
â”œâ”€â”€ Parameters.ipynb               # ConfiguraÃ§Ãµes dinÃ¢micas
â”œâ”€â”€ Bronze_Layer.ipynb             # IngestÃ£o de dados raw
â”œâ”€â”€ Silver_Products.ipynb          # TransformaÃ§Ã£o de produtos
â”œâ”€â”€ Silver_Customers.ipynb         # TransformaÃ§Ã£o de clientes
â”œâ”€â”€ Silver_Orders.ipynb            # TransformaÃ§Ã£o de pedidos
â”œâ”€â”€ Silver_Regions.ipynb           # TransformaÃ§Ã£o de regiÃµes
â”œâ”€â”€ Gold_Products.ipynb            # DimensÃ£o produtos
â”œâ”€â”€ Gold_Customers.ipynb           # DimensÃ£o clientes
â””â”€â”€ Gold_Orders.ipynb              # Fato pedidos
```

---

## ğŸš€ Como Executar

### âœ… PrÃ©-requisitos
- Azure Subscription ativa  
- Azure Databricks Workspace  
- Azure Data Lake Storage Gen2  
- Unity Catalog habilitado  

### âš™ï¸ ConfiguraÃ§Ã£o RÃ¡pida

```bash
# Clone o repositÃ³rio
git clone https://github.com/ViniciusLabruna/pipeline-vendas-azure-databricks.git
```

1. Importe os notebooks no Databricks  
2. Configure as variÃ¡veis de ambiente (storage, containers, credenciais)  
3. Execute os notebooks na seguinte ordem:

### ğŸ“Œ Ordem de ExecuÃ§Ã£o

1. `Parameters.ipynb` â€“ ConfiguraÃ§Ã£o  
2. `Bronze_Layer.ipynb` â€“ IngestÃ£o para cada dataset  
3. `Silver_*.ipynb` â€“ TransformaÃ§Ãµes (em paralelo)  
4. `Gold_*.ipynb` â€“ Modelagem dimensional (em paralelo)  

---

## ğŸ” Principais Aprendizados

### ğŸ“ Arquitetura Moderna
- Medallion Architecture implementada na prÃ¡tica  
- SeparaÃ§Ã£o por camadas (Bronze, Silver, Gold)  
- Processamento incremental com performance  

### ğŸ’¡ Tecnologias de Ponta
- Azure Databricks como plataforma unificada  
- Delta Lake com suporte a ACID e Time Travel  
- Unity Catalog para governanÃ§a de dados  

### âš™ï¸ Engenharia de Dados AvanÃ§ada
- Streaming com Autoloader  
- SCD Type 2 e modelagem dimensional  
- Performance tuning com Z-Ordering  

---

## ğŸ§ª Engenharia de Dados Moderna

âœ… Arquitetura Cloud-native  
âœ… Streaming + Batch  
âœ… GovernanÃ§a e Qualidade  
âœ… OtimizaÃ§Ã£o e Escalabilidade  
âœ… Design de Pipelines ReutilizÃ¡veis  

---

## ğŸ§° Ferramentas Enterprise

- Azure Databricks  
- PySpark  
- Delta Lake  
- Delta Live Tables  
- Unity Catalog  
- Azure Data Lake  
- Databricks Workflows  
- Azure Resource Manager  
